{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ML Pipeline Preparation\n",
    "Follow the instructions below to help you create your ML pipeline.\n",
    "### 1. Import libraries and load data from database.\n",
    "- Import Python libraries\n",
    "- Load dataset from database with [`read_sql_table`](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.read_sql_table.html)\n",
    "- Define feature and target variables X and Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import nltk\n",
    "import pickle\n",
    "\n",
    "from sqlalchemy import create_engine\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package words to /root/nltk_data...\n",
      "[nltk_data]   Package words is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('stopwords')\n",
    "nltk.download('words')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('punkt')\n",
    "#nltk.download('averaged_perceptron_tagger')\n",
    "#nltk.download('maxent_ne_chunker')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>related</th>\n",
       "      <th>request</th>\n",
       "      <th>offer</th>\n",
       "      <th>aid_related</th>\n",
       "      <th>medical_help</th>\n",
       "      <th>medical_products</th>\n",
       "      <th>search_and_rescue</th>\n",
       "      <th>security</th>\n",
       "      <th>military</th>\n",
       "      <th>child_alone</th>\n",
       "      <th>...</th>\n",
       "      <th>aid_centers</th>\n",
       "      <th>other_infrastructure</th>\n",
       "      <th>weather_related</th>\n",
       "      <th>floods</th>\n",
       "      <th>storm</th>\n",
       "      <th>fire</th>\n",
       "      <th>earthquake</th>\n",
       "      <th>cold</th>\n",
       "      <th>other_weather</th>\n",
       "      <th>direct_report</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 36 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   related  request  offer  aid_related  medical_help  medical_products  \\\n",
       "0        1        0      0            0             0                 0   \n",
       "1        1        0      0            1             0                 0   \n",
       "2        1        0      0            0             0                 0   \n",
       "3        1        1      0            1             0                 1   \n",
       "4        1        0      0            0             0                 0   \n",
       "\n",
       "   search_and_rescue  security  military  child_alone      ...        \\\n",
       "0                  0         0         0            0      ...         \n",
       "1                  0         0         0            0      ...         \n",
       "2                  0         0         0            0      ...         \n",
       "3                  0         0         0            0      ...         \n",
       "4                  0         0         0            0      ...         \n",
       "\n",
       "   aid_centers  other_infrastructure  weather_related  floods  storm  fire  \\\n",
       "0            0                     0                0       0      0     0   \n",
       "1            0                     0                1       0      1     0   \n",
       "2            0                     0                0       0      0     0   \n",
       "3            0                     0                0       0      0     0   \n",
       "4            0                     0                0       0      0     0   \n",
       "\n",
       "   earthquake  cold  other_weather  direct_report  \n",
       "0           0     0              0              0  \n",
       "1           0     0              0              0  \n",
       "2           0     0              0              0  \n",
       "3           0     0              0              0  \n",
       "4           0     0              0              0  \n",
       "\n",
       "[5 rows x 36 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load data from database\n",
    "engine = create_engine('sqlite:///DisasterResponse.db')\n",
    "df = pd.read_sql_table(\"CategorizedResponse\", engine)\n",
    "X = df[\"message\"]\n",
    "y = df.drop([\"id\", \"message\", \"original\", \"genre\"], axis = \"columns\")\n",
    "y.head()\n",
    "#df.head()\n",
    "#X.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Write a tokenization function to process your text data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['weather', 'update', 'cold', 'front', 'cuba', 'could', 'pas', 'haiti']\n"
     ]
    }
   ],
   "source": [
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "def tokenize(text):\n",
    "    \"\"\" Tokenize \"\"\"\n",
    "    \n",
    "    # Normalize text\n",
    "    # Replace non-alphanumeric characters with space, convert to lower and remove trailing spaces \n",
    "    text = re.sub(\"[^a-zA-Z09]\", \" \", text).lower().strip()\n",
    "    # To be extra-clean remove double spaces\n",
    "    text = re.sub(\"\\s{2,}\", \" \", text)\n",
    "    \n",
    "    # After normalization, tokenize text into tokens, remove stop words and lemmatize\n",
    "    tokens = word_tokenize(text)\n",
    "    # Remove stop words\n",
    "    tokens = [lemmatizer.lemmatize(word) for word in tokens if word not in stopwords.words(\"english\")]\n",
    "    \n",
    "    return tokens\n",
    "\n",
    "print(tokenize(X[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Build a machine learning pipeline\n",
    "This machine pipeline should take in the `message` column as input and output classification results on the other 36 categories in the dataset. You may find the [MultiOutputClassifier](http://scikit-learn.org/stable/modules/generated/sklearn.multioutput.MultiOutputClassifier.html) helpful for predicting multiple target variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createPipeline(classifier):\n",
    "    \"\"\" Function to create the pipeline with tokenization plus classifier wrapped in multi output \"\"\"\n",
    "    return Pipeline([\n",
    "        ('vect', CountVectorizer(tokenizer = tokenize)),\n",
    "        ('tfidf', TfidfTransformer()),\n",
    "        ('clf', MultiOutputClassifier(classifier))\n",
    "    ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Train pipeline\n",
    "- Split data into train and test sets\n",
    "- Train pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into train and test sets\n",
    "# Note: Regarding some problems I had, in the future I should look into \"stratify = y\" option and StratifiedShuffleSplit\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19661\n"
     ]
    }
   ],
   "source": [
    "print(len(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note: Old code before I switched to pipeline, kept here for future debugging if something doesn't work\n",
    "\n",
    "#vect = CountVectorizer(tokenizer = tokenize)\n",
    "#tfidf = TfidfTransformer()\n",
    "#moc = MultiOutputClassifier(RandomForestClassifier())\n",
    "#X_train_counts = vect.fit_transform(X_train)\n",
    "#X_train_tfidf = tfidf.fit_transform(X_train_counts)\n",
    "\n",
    "# Note: I had multiple problems here because I used SVC and there were exclusively 0 values in child_alone. \n",
    "# Fixed by removing the obsolete target child_alone and using a different classifier.\n",
    "#moc.fit(X_train_tfidf, y_train)\n",
    "\n",
    "# Vectorize test input data\n",
    "# Note: Got errors here because I used fit_transform instead of transform and because I created nwwe vect and tfidf instances.\n",
    "#X_test_counts = vect.transform(X_test)\n",
    "#X_test_tfidf = tfidf.transform(X_test_counts)\n",
    "\n",
    "# Note: When using SVC as clsf. I got all 0 predictions for the labels. Probably need to tune SVC. Fixed by using differnt clsf.\n",
    "#y_pred = moc.predict(X_test_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "     steps=[('vect', CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "        ngram_range=(1, 1), preprocessor=None, stop_words=None,\n",
       "        strip...oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False),\n",
       "           n_jobs=1))])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit the classification model\n",
    "pipeline = createPipeline(RandomForestClassifier())\n",
    "pipeline.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Test your model\n",
    "Report the f1 score, precision and recall for each output category of the dataset. You can do this by iterating through the columns and calling sklearn's `classification_report` on each."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "y_pred = pipeline.predict(X_test)\n",
    "\n",
    "print (y_pred[1009]) # sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                        precision    recall  f1-score   support\n",
      "\n",
      "               related       0.85      0.91      0.88      5001\n",
      "               request       0.79      0.42      0.55      1093\n",
      "                 offer       0.00      0.00      0.00        32\n",
      "           aid_related       0.77      0.60      0.68      2700\n",
      "          medical_help       0.62      0.11      0.18       532\n",
      "      medical_products       0.70      0.07      0.12       345\n",
      "     search_and_rescue       0.75      0.04      0.07       165\n",
      "              security       0.40      0.02      0.03       127\n",
      "              military       0.62      0.09      0.16       197\n",
      "           child_alone       0.00      0.00      0.00         0\n",
      "                 water       0.83      0.28      0.42       408\n",
      "                  food       0.83      0.34      0.49       723\n",
      "               shelter       0.80      0.35      0.49       590\n",
      "              clothing       0.81      0.14      0.23        95\n",
      "                 money       0.56      0.11      0.18       138\n",
      "        missing_people       1.00      0.01      0.03        74\n",
      "              refugees       0.70      0.03      0.06       223\n",
      "                 death       0.83      0.19      0.31       301\n",
      "             other_aid       0.47      0.05      0.08       865\n",
      "infrastructure_related       0.45      0.01      0.02       410\n",
      "             transport       0.69      0.08      0.14       288\n",
      "             buildings       0.85      0.11      0.19       331\n",
      "           electricity       0.57      0.03      0.05       144\n",
      "                 tools       0.00      0.00      0.00        46\n",
      "             hospitals       0.00      0.00      0.00        60\n",
      "                 shops       0.00      0.00      0.00        29\n",
      "           aid_centers       0.00      0.00      0.00        77\n",
      "  other_infrastructure       0.00      0.00      0.00       277\n",
      "       weather_related       0.83      0.63      0.72      1816\n",
      "                floods       0.89      0.37      0.52       546\n",
      "                 storm       0.73      0.47      0.58       596\n",
      "                  fire       1.00      0.03      0.06        67\n",
      "            earthquake       0.90      0.74      0.81       630\n",
      "                  cold       0.79      0.12      0.21       122\n",
      "         other_weather       0.43      0.04      0.07       319\n",
      "         direct_report       0.72      0.31      0.43      1265\n",
      "\n",
      "           avg / total       0.75      0.49      0.54     20632\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/metrics/classification.py:1137: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "# Note: I had problems here becuase the data wasn't clean. Fixed by removing \"2\" from target \"related\" in ETL.\n",
    "print(classification_report(y_test, y_pred, target_names = y.columns))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Improve your model\n",
    "Use grid search to find better parameters. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a smaller training set to run gridsearch on\n",
    "cv_size_divisor = 2.5\n",
    "\n",
    "X_cv_reduced = X_train.copy(deep = True)[:int(len(X_train) / cv_size_divisor)]\n",
    "y_cv_reduced = y_train.copy(deep = True)[:int(len(y_train) / cv_size_divisor)]\n",
    "\n",
    "#print(len(X_cv_reduced))\n",
    "#print(len(y_cv_reduced))\n",
    "#X_cv_reduced.head()\n",
    "#y_cv_reduced.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#RandomForestClassifier().get_params().keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 8 candidates, totalling 24 fits\n",
      "[CV] clf__estimator__n_estimators=10, vect__max_df=0.5, vect__ngram_range=(1, 1) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/metrics/classification.py:1137: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  clf__estimator__n_estimators=10, vect__max_df=0.5, vect__ngram_range=(1, 1), score=0.2102804340872405, total=  44.0s\n",
      "[CV] clf__estimator__n_estimators=10, vect__max_df=0.5, vect__ngram_range=(1, 1) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   1 out of   1 | elapsed:  1.1min remaining:    0.0s\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/metrics/classification.py:1137: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  clf__estimator__n_estimators=10, vect__max_df=0.5, vect__ngram_range=(1, 1), score=0.22339417089733551, total=  44.0s\n",
      "[CV] clf__estimator__n_estimators=10, vect__max_df=0.5, vect__ngram_range=(1, 1) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   2 out of   2 | elapsed:  2.3min remaining:    0.0s\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/metrics/classification.py:1137: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  clf__estimator__n_estimators=10, vect__max_df=0.5, vect__ngram_range=(1, 1), score=0.21879104606174185, total=  44.2s\n",
      "[CV] clf__estimator__n_estimators=10, vect__max_df=0.5, vect__ngram_range=(1, 2) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   3 out of   3 | elapsed:  3.4min remaining:    0.0s\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/metrics/classification.py:1137: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  clf__estimator__n_estimators=10, vect__max_df=0.5, vect__ngram_range=(1, 2), score=0.19408957137257765, total=  50.7s\n",
      "[CV] clf__estimator__n_estimators=10, vect__max_df=0.5, vect__ngram_range=(1, 2) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   4 out of   4 | elapsed:  4.7min remaining:    0.0s\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/metrics/classification.py:1137: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  clf__estimator__n_estimators=10, vect__max_df=0.5, vect__ngram_range=(1, 2), score=0.18177052624408957, total=  50.4s\n",
      "[CV] clf__estimator__n_estimators=10, vect__max_df=0.5, vect__ngram_range=(1, 2) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:  5.9min remaining:    0.0s\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/metrics/classification.py:1137: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  clf__estimator__n_estimators=10, vect__max_df=0.5, vect__ngram_range=(1, 2), score=0.18154769604637805, total=  51.1s\n",
      "[CV] clf__estimator__n_estimators=10, vect__max_df=1.0, vect__ngram_range=(1, 1) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   6 out of   6 | elapsed:  7.2min remaining:    0.0s\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/metrics/classification.py:1137: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  clf__estimator__n_estimators=10, vect__max_df=1.0, vect__ngram_range=(1, 1), score=0.21304886973003181, total=  43.7s\n",
      "[CV] clf__estimator__n_estimators=10, vect__max_df=1.0, vect__ngram_range=(1, 1) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   7 out of   7 | elapsed:  8.3min remaining:    0.0s\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/metrics/classification.py:1137: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  clf__estimator__n_estimators=10, vect__max_df=1.0, vect__ngram_range=(1, 1), score=0.19973364611569344, total=  44.4s\n",
      "[CV] clf__estimator__n_estimators=10, vect__max_df=1.0, vect__ngram_range=(1, 1) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   8 out of   8 | elapsed:  9.5min remaining:    0.0s\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/metrics/classification.py:1137: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  clf__estimator__n_estimators=10, vect__max_df=1.0, vect__ngram_range=(1, 1), score=0.19406909871682637, total=  44.1s\n",
      "[CV] clf__estimator__n_estimators=10, vect__max_df=1.0, vect__ngram_range=(1, 2) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   9 out of   9 | elapsed: 10.6min remaining:    0.0s\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/metrics/classification.py:1137: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  clf__estimator__n_estimators=10, vect__max_df=1.0, vect__ngram_range=(1, 2), score=0.17194107402246614, total=  50.4s\n",
      "[CV] clf__estimator__n_estimators=10, vect__max_df=1.0, vect__ngram_range=(1, 2) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/metrics/classification.py:1137: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  clf__estimator__n_estimators=10, vect__max_df=1.0, vect__ngram_range=(1, 2), score=0.1750614583680785, total=  50.3s\n",
      "[CV] clf__estimator__n_estimators=10, vect__max_df=1.0, vect__ngram_range=(1, 2) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/metrics/classification.py:1137: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  clf__estimator__n_estimators=10, vect__max_df=1.0, vect__ngram_range=(1, 2), score=0.1926039674630515, total=  50.5s\n",
      "[CV] clf__estimator__n_estimators=30, vect__max_df=0.5, vect__ngram_range=(1, 1) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/metrics/classification.py:1137: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  clf__estimator__n_estimators=30, vect__max_df=0.5, vect__ngram_range=(1, 1), score=0.20421791120141877, total= 1.0min\n",
      "[CV] clf__estimator__n_estimators=30, vect__max_df=0.5, vect__ngram_range=(1, 1) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/metrics/classification.py:1137: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  clf__estimator__n_estimators=30, vect__max_df=0.5, vect__ngram_range=(1, 1), score=0.22030640237816593, total= 1.0min\n",
      "[CV] clf__estimator__n_estimators=30, vect__max_df=0.5, vect__ngram_range=(1, 1) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/metrics/classification.py:1137: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  clf__estimator__n_estimators=30, vect__max_df=0.5, vect__ngram_range=(1, 1), score=0.22094729653069875, total= 1.0min\n",
      "[CV] clf__estimator__n_estimators=30, vect__max_df=0.5, vect__ngram_range=(1, 2) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/metrics/classification.py:1137: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  clf__estimator__n_estimators=30, vect__max_df=0.5, vect__ngram_range=(1, 2), score=0.19104563009345235, total= 1.3min\n",
      "[CV] clf__estimator__n_estimators=30, vect__max_df=0.5, vect__ngram_range=(1, 2) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/metrics/classification.py:1137: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  clf__estimator__n_estimators=30, vect__max_df=0.5, vect__ngram_range=(1, 2), score=0.18707438189819586, total= 1.3min\n",
      "[CV] clf__estimator__n_estimators=30, vect__max_df=0.5, vect__ngram_range=(1, 2) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/metrics/classification.py:1137: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  clf__estimator__n_estimators=30, vect__max_df=0.5, vect__ngram_range=(1, 2), score=0.19898452081005485, total= 1.4min\n",
      "[CV] clf__estimator__n_estimators=30, vect__max_df=1.0, vect__ngram_range=(1, 1) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/metrics/classification.py:1137: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  clf__estimator__n_estimators=30, vect__max_df=1.0, vect__ngram_range=(1, 1), score=0.21264006626498363, total= 1.0min\n",
      "[CV] clf__estimator__n_estimators=30, vect__max_df=1.0, vect__ngram_range=(1, 1) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/metrics/classification.py:1137: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  clf__estimator__n_estimators=30, vect__max_df=1.0, vect__ngram_range=(1, 1), score=0.21002938274901115, total= 1.0min\n",
      "[CV] clf__estimator__n_estimators=30, vect__max_df=1.0, vect__ngram_range=(1, 1) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/metrics/classification.py:1137: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  clf__estimator__n_estimators=30, vect__max_df=1.0, vect__ngram_range=(1, 1), score=0.218240052323343, total= 1.0min\n",
      "[CV] clf__estimator__n_estimators=30, vect__max_df=1.0, vect__ngram_range=(1, 2) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/metrics/classification.py:1137: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  clf__estimator__n_estimators=30, vect__max_df=1.0, vect__ngram_range=(1, 2), score=0.18511504942243764, total= 1.3min\n",
      "[CV] clf__estimator__n_estimators=30, vect__max_df=1.0, vect__ngram_range=(1, 2) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/metrics/classification.py:1137: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  clf__estimator__n_estimators=30, vect__max_df=1.0, vect__ngram_range=(1, 2), score=0.18907456136018874, total= 1.3min\n",
      "[CV] clf__estimator__n_estimators=30, vect__max_df=1.0, vect__ngram_range=(1, 2) \n"
     ]
    }
   ],
   "source": [
    "# Run gridsearch\n",
    "parameters = {\n",
    "    'vect__ngram_range': ((1, 1), (1, 2)),\n",
    "    'vect__max_df': (0.5, 1.0),\n",
    "    'clf__estimator__n_estimators': [10, 30] \n",
    "}\n",
    "\n",
    "cv = GridSearchCV(estimator = pipeline, param_grid = parameters, scoring='f1_macro', cv = None, n_jobs = -1, verbose = 10)\n",
    "cv.fit(X_cv_reduced, y_cv_reduced)\n",
    "\n",
    "y_pred_cv = cv.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Test your model\n",
    "Show the accuracy, precision, and recall of the tuned model.  \n",
    "\n",
    "Since this project focuses on code quality, process, and  pipelines, there is no minimum performance metric needed to pass. However, make sure to fine tune your models for accuracy, precision and recall to make your project stand out - especially for your portfolio!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test, y_pred_cv, target_names = y.columns))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8. Try improving your model further. Here are a few ideas:\n",
    "* try other machine learning algorithms\n",
    "* add other features besides the TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/pandas/core/frame.py:3697: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  errors=errors)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LinearSVC\n",
      "                        precision    recall  f1-score   support\n",
      "\n",
      "               related       0.86      0.91      0.89      5001\n",
      "               request       0.76      0.59      0.67      1093\n",
      "                 offer       0.00      0.00      0.00        32\n",
      "           aid_related       0.72      0.67      0.70      2700\n",
      "          medical_help       0.59      0.30      0.40       532\n",
      "      medical_products       0.64      0.30      0.41       345\n",
      "     search_and_rescue       0.66      0.15      0.25       165\n",
      "              security       0.57      0.03      0.06       127\n",
      "              military       0.50      0.27      0.36       197\n",
      "                 water       0.77      0.60      0.67       408\n",
      "                  food       0.82      0.69      0.75       723\n",
      "               shelter       0.75      0.55      0.64       590\n",
      "              clothing       0.75      0.44      0.56        95\n",
      "                 money       0.53      0.22      0.32       138\n",
      "        missing_people       0.87      0.18      0.29        74\n",
      "              refugees       0.60      0.23      0.33       223\n",
      "                 death       0.74      0.49      0.59       301\n",
      "             other_aid       0.44      0.20      0.28       865\n",
      "infrastructure_related       0.39      0.10      0.16       410\n",
      "             transport       0.71      0.19      0.31       288\n",
      "             buildings       0.77      0.36      0.49       331\n",
      "           electricity       0.68      0.26      0.38       144\n",
      "                 tools       0.00      0.00      0.00        46\n",
      "             hospitals       0.62      0.08      0.15        60\n",
      "                 shops       0.00      0.00      0.00        29\n",
      "           aid_centers       0.50      0.04      0.07        77\n",
      "  other_infrastructure       0.32      0.05      0.09       277\n",
      "       weather_related       0.82      0.71      0.76      1816\n",
      "                floods       0.87      0.54      0.67       546\n",
      "                 storm       0.73      0.59      0.65       596\n",
      "                  fire       0.78      0.31      0.45        67\n",
      "            earthquake       0.90      0.74      0.81       630\n",
      "                  cold       0.71      0.34      0.46       122\n",
      "         other_weather       0.47      0.17      0.25       319\n",
      "         direct_report       0.67      0.48      0.56      1265\n",
      "\n",
      "           avg / total       0.74      0.60      0.64     20632\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "# 1 Try a different classifier: LinearSVC\n",
    "\n",
    "# SVC will not accept singular class, remove offending column\n",
    "y_test.drop([\"child_alone\"], axis = \"columns\", inplace = True)\n",
    "y_train.drop([\"child_alone\"], axis = \"columns\", inplace = True)\n",
    "\n",
    "pipeline = createPipeline(LinearSVC())\n",
    "\n",
    "pipeline.fit(X_train, y_train)\n",
    "y_pred = pipeline.predict(X_test)\n",
    "\n",
    "print(\"LinearSVC\")\n",
    "print(classification_report(y_test, y_pred, target_names = y_train.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 4 candidates, totalling 12 fits\n",
      "[CV] vect__max_df=0.5, vect__ngram_range=(1, 1) ......................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  vect__max_df=0.5, vect__ngram_range=(1, 1), score=0.3483433719243196, total=  40.6s\n",
      "[CV] vect__max_df=0.5, vect__ngram_range=(1, 1) ......................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   1 out of   1 | elapsed:  1.1min remaining:    0.0s\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  vect__max_df=0.5, vect__ngram_range=(1, 1), score=0.36111489354290727, total=  40.6s\n",
      "[CV] vect__max_df=0.5, vect__ngram_range=(1, 1) ......................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   2 out of   2 | elapsed:  2.2min remaining:    0.0s\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  vect__max_df=0.5, vect__ngram_range=(1, 1), score=0.3521670406171794, total=  40.9s\n",
      "[CV] vect__max_df=0.5, vect__ngram_range=(1, 2) ......................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   3 out of   3 | elapsed:  3.4min remaining:    0.0s\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  vect__max_df=0.5, vect__ngram_range=(1, 2), score=0.3390865145530255, total=  41.7s\n",
      "[CV] vect__max_df=0.5, vect__ngram_range=(1, 2) ......................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   4 out of   4 | elapsed:  4.5min remaining:    0.0s\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  vect__max_df=0.5, vect__ngram_range=(1, 2), score=0.3608932124169923, total=  42.1s\n",
      "[CV] vect__max_df=0.5, vect__ngram_range=(1, 2) ......................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:  5.7min remaining:    0.0s\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  vect__max_df=0.5, vect__ngram_range=(1, 2), score=0.34353783534064103, total=  41.9s\n",
      "[CV] vect__max_df=1.0, vect__ngram_range=(1, 1) ......................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   6 out of   6 | elapsed:  6.8min remaining:    0.0s\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  vect__max_df=1.0, vect__ngram_range=(1, 1), score=0.348296860884267, total=  40.8s\n",
      "[CV] vect__max_df=1.0, vect__ngram_range=(1, 1) ......................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   7 out of   7 | elapsed:  7.9min remaining:    0.0s\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  vect__max_df=1.0, vect__ngram_range=(1, 1), score=0.36111489354290727, total=  41.0s\n",
      "[CV] vect__max_df=1.0, vect__ngram_range=(1, 1) ......................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   8 out of   8 | elapsed:  9.1min remaining:    0.0s\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  vect__max_df=1.0, vect__ngram_range=(1, 1), score=0.3521670406171794, total=  40.7s\n",
      "[CV] vect__max_df=1.0, vect__ngram_range=(1, 2) ......................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   9 out of   9 | elapsed: 10.2min remaining:    0.0s\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  vect__max_df=1.0, vect__ngram_range=(1, 2), score=0.3390865145530255, total=  41.4s\n",
      "[CV] vect__max_df=1.0, vect__ngram_range=(1, 2) ......................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  vect__max_df=1.0, vect__ngram_range=(1, 2), score=0.3608932124169923, total=  41.8s\n",
      "[CV] vect__max_df=1.0, vect__ngram_range=(1, 2) ......................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  vect__max_df=1.0, vect__ngram_range=(1, 2), score=0.34353783534064103, total=  41.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  12 out of  12 | elapsed: 13.6min finished\n"
     ]
    }
   ],
   "source": [
    "parameters = {\n",
    "    'vect__ngram_range': ((1, 1), (1, 2)),\n",
    "    'vect__max_df': (0.5, 1.0)\n",
    "}\n",
    "\n",
    "cv = GridSearchCV(estimator = pipeline, param_grid = parameters, scoring='f1_macro', cv = None, n_jobs = -1, verbose = 10)\n",
    "cv.fit(X_cv_reduced, y_cv_reduced)\n",
    "\n",
    "y_pred_cv = cv.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                        precision    recall  f1-score   support\n",
      "\n",
      "               related       0.86      0.91      0.88      5001\n",
      "               request       0.75      0.58      0.65      1093\n",
      "                 offer       0.00      0.00      0.00        32\n",
      "           aid_related       0.71      0.68      0.69      2700\n",
      "          medical_help       0.57      0.27      0.37       532\n",
      "      medical_products       0.66      0.28      0.39       345\n",
      "     search_and_rescue       0.74      0.17      0.28       165\n",
      "              security       0.25      0.01      0.02       127\n",
      "              military       0.54      0.18      0.27       197\n",
      "           child_alone       0.75      0.61      0.67       408\n",
      "                 water       0.82      0.66      0.73       723\n",
      "                  food       0.73      0.52      0.61       590\n",
      "               shelter       0.76      0.40      0.52        95\n",
      "              clothing       0.53      0.15      0.24       138\n",
      "                 money       0.73      0.11      0.19        74\n",
      "        missing_people       0.67      0.14      0.24       223\n",
      "              refugees       0.76      0.40      0.52       301\n",
      "                 death       0.43      0.21      0.28       865\n",
      "             other_aid       0.45      0.09      0.14       410\n",
      "infrastructure_related       0.68      0.17      0.28       288\n",
      "             transport       0.73      0.31      0.43       331\n",
      "             buildings       0.78      0.17      0.28       144\n",
      "           electricity       0.00      0.00      0.00        46\n",
      "                 tools       0.80      0.07      0.12        60\n",
      "             hospitals       0.00      0.00      0.00        29\n",
      "                 shops       0.60      0.04      0.07        77\n",
      "           aid_centers       0.38      0.05      0.09       277\n",
      "  other_infrastructure       0.81      0.70      0.76      1816\n",
      "       weather_related       0.87      0.52      0.65       546\n",
      "                floods       0.73      0.57      0.64       596\n",
      "                 storm       0.84      0.24      0.37        67\n",
      "                  fire       0.89      0.73      0.80       630\n",
      "            earthquake       0.73      0.25      0.37       122\n",
      "                  cold       0.45      0.12      0.19       319\n",
      "         other_weather       0.65      0.46      0.54      1265\n",
      "\n",
      "           avg / total       0.73      0.58      0.63     20632\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/sklearn/metrics/classification.py:1428: UserWarning: labels size, 35, does not match size of target_names, 36\n",
      "  .format(len(labels), len(target_names))\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred_cv, target_names = y.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AdaBoost\n",
      "                        precision    recall  f1-score   support\n",
      "\n",
      "               related       0.80      0.96      0.88      5001\n",
      "               request       0.78      0.52      0.62      1093\n",
      "           aid_related       0.76      0.58      0.66      2700\n",
      "          medical_help       0.58      0.24      0.34       532\n",
      "      medical_products       0.63      0.32      0.42       345\n",
      "     search_and_rescue       0.56      0.16      0.25       165\n",
      "              military       0.53      0.24      0.33       197\n",
      "                 water       0.76      0.67      0.71       408\n",
      "                  food       0.81      0.66      0.73       723\n",
      "               shelter       0.74      0.55      0.63       590\n",
      "              clothing       0.71      0.36      0.48        95\n",
      "                 money       0.52      0.30      0.38       138\n",
      "        missing_people       0.58      0.19      0.29        74\n",
      "              refugees       0.59      0.24      0.34       223\n",
      "                 death       0.80      0.46      0.58       301\n",
      "             other_aid       0.52      0.15      0.23       865\n",
      "infrastructure_related       0.39      0.09      0.15       410\n",
      "             transport       0.68      0.21      0.32       288\n",
      "             buildings       0.70      0.42      0.53       331\n",
      "           electricity       0.62      0.20      0.30       144\n",
      "  other_infrastructure       0.32      0.08      0.12       277\n",
      "       weather_related       0.86      0.69      0.76      1816\n",
      "                floods       0.86      0.55      0.68       546\n",
      "                 storm       0.77      0.45      0.57       596\n",
      "                  fire       0.50      0.16      0.25        67\n",
      "            earthquake       0.89      0.80      0.84       630\n",
      "                  cold       0.71      0.34      0.46       122\n",
      "         other_weather       0.41      0.14      0.21       319\n",
      "         direct_report       0.68      0.38      0.48      1265\n",
      "\n",
      "           avg / total       0.73      0.59      0.63     20261\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 2 Try another classifier: AdaBoost. \n",
    "# Also, since the dataset is imbalanced, remove columns with insufficient data. \n",
    "\n",
    "labelsToDrop = ['offer', 'security', 'tools', 'hospitals', 'shops', 'aid_centers']\n",
    "y_TrainDroppedLabels = y_train.copy()\n",
    "y_TrainDroppedLabels.drop(labelsToDrop, axis = \"columns\", inplace = True)\n",
    "y_TestDroppedLabels = y_test.copy()\n",
    "y_TestDroppedLabels.drop(labelsToDrop, axis = \"columns\", inplace = True)\n",
    "\n",
    "pipeline = createPipeline(AdaBoostClassifier())\n",
    "\n",
    "pipeline.fit(X_train, y_TrainDroppedLabels)\n",
    "y_pred = pipeline.predict(X_test)\n",
    "\n",
    "print(\"AdaBoost\")\n",
    "print(classification_report(y_TestDroppedLabels, y_pred, target_names = y_TestDroppedLabels.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'y_TrainDroppedLabels' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-b2ecab2a6cb3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mpipeline\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreatePipeline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mLinearSVC\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mpipeline\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_TrainDroppedLabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpipeline\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'y_TrainDroppedLabels' is not defined"
     ]
    }
   ],
   "source": [
    "pipeline = createPipeline(LinearSVC())\n",
    "\n",
    "pipeline.fit(X_train, y_TrainDroppedLabels)\n",
    "y_pred = pipeline.predict(X_test)\n",
    "\n",
    "print(\"LinearSVC with dropped Labels\")\n",
    "print(classification_report(y_TestDroppedLabels, y_pred, target_names = y_TestDroppedLabels.columns))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9. Export your model as a pickle file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The last used pipeline is the best performing one\n",
    "pickle.dump(pipeline, open(\"model.pickle\",'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10. Use this notebook to complete `train.py`\n",
    "Use the template file attached in the Resources folder to write a script that runs the steps above to create a database and export a model based on a new dataset specified by the user."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['related', 'request', 'aid_related', 'other_aid', 'weather_related',\n",
      "       'earthquake', 'direct_report'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "def toLabels(prediction):\n",
    "    return y_TestDroppedLabels.columns[prediction[0] == 1]\n",
    "\n",
    "print(\n",
    "    toLabels(\n",
    "        pipeline.predict([\"there was an earthquake please help\"]\n",
    ")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
